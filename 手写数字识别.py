import os
import csv
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torchvision
from torch.utils.data import DataLoader
from PIL import Image
from torchinfo import summary

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. æ”¹è¿›åçš„æ¨¡å‹ç»“æ„ï¼ˆå‡†ç¡®ç‡æ›´é«˜ï¼‰
class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=4)
        self.pool1 = nn.MaxPool2d(2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)
        self.pool2 = nn.MaxPool2d(2)
        self.fc1 = nn.Linear(1600, 32)
        self.fc2 = nn.Linear(32, 10)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = torch.flatten(x, start_dim=1)
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# 2. æ•°æ®åŠ è½½å™¨
def get_data_loader(is_train):
    transform = torchvision.transforms.ToTensor()
    dataset = torchvision.datasets.MNIST(root="./data", train=is_train, download=True, transform=transform)
    return DataLoader(dataset, batch_size=32, shuffle=is_train)

# è®­ç»ƒå¾ªç¯
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°ï¼Œä¸€å…±60000å¼ å›¾ç‰‡
    num_batches = len(dataloader)  # æ‰¹æ¬¡æ•°ç›®ï¼Œ1875ï¼ˆ60000/32ï¼‰
    train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
    for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾
        X, y = X.to(device), y.to(device)
        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)  # ç½‘ç»œè¾“å‡º
        loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
        # åå‘ä¼ æ’­
        optimizer.zero_grad()  # gradå±æ€§å½’é›¶
        loss.backward()  # åå‘ä¼ æ’­
        optimizer.step()  # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
        # è®°å½•accä¸loss
        train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
    train_acc /= size
    train_loss /= num_batches
    return train_acc, train_loss

# æµ‹è¯•å‡†ç¡®ç‡è¯„ä¼°
def test(dataloader, model, loss_fn):
    size = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€å…±10000å¼ å›¾ç‰‡
    num_batches = len(dataloader)  # æ‰¹æ¬¡æ•°ç›®ï¼Œ313ï¼ˆ10000/32=312.5ï¼Œå‘ä¸Šå–æ•´ï¼‰
    test_loss, test_acc = 0, 0
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:
            imgs, target = imgs.to(device), target.to(device)
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss = loss_fn(target_pred, target)
            test_loss += loss.item()
            test_acc += (target_pred.argmax(1) == target).type(torch.float).sum().item()
    test_acc /= size
    test_loss /= num_batches
    return test_acc, test_loss

# 3. æ¨¡å‹è®­ç»ƒå¹¶ä¿å­˜
def train_and_save_model(model_path):
    train_loader = get_data_loader(True)
    test_loader = get_data_loader(False)
    net = Model().to(device)
    summary(net)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)

    epochs = 4
    train_loss_list, train_acc_list = [], []
    test_loss_list, test_acc_list = [], []

    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(epochs):
        net.train()
        epoch_train_acc, epoch_train_loss = train(train_loader, net, loss_fn, optimizer)
        net.eval()
        epoch_test_acc, epoch_test_loss = test(test_loader, net, loss_fn)
        train_acc_list.append(epoch_train_acc)
        train_loss_list.append(epoch_train_loss)
        test_acc_list.append(epoch_test_acc)
        test_loss_list.append(epoch_test_loss)
        print(f'Epoch:{epoch+1:2d}, Train_acc:{epoch_train_acc*100:.1f}%, Train_loss:{epoch_train_loss:.3f}, Test_acc:{epoch_test_acc*100:.1f}%, Test_loss:{epoch_test_loss:.3f}')

    torch.save(net.state_dict(), model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

# 5. è‡ªå®šä¹‰æ•°æ®é¢„æµ‹å¹¶è¾“å‡º CSVï¼ˆæ ¼å¼: id,labelï¼‰
def predict_custom_images(model_path, folder_path, output_csv):
    net = Model().to(device)
    net.load_state_dict(torch.load(model_path))
    net.eval()

    transform = torchvision.transforms.Compose([
        torchvision.transforms.Grayscale(),
        torchvision.transforms.Resize((28, 28)),
        torchvision.transforms.ToTensor()
    ])

    results = []
    files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith('.png')])

    for idx, file_name in enumerate(files):
        img_path = os.path.join(folder_path, file_name)
        img = Image.open(img_path)
        tensor = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            output = net(tensor)
            pred = torch.argmax(output, dim=1).item()
            results.append((idx, pred))  # indexå½“ä½œid

    with open(output_csv, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["id", "label"])
        writer.writerows(results)

    print(f"ğŸ“„ CSV æ–‡ä»¶å·²ä¿å­˜ï¼š{output_csv}")

# 6. ä¸»æ‰§è¡Œæµç¨‹
if __name__ == "__main__":
    model_path = "better_digit_model.pth"
    image_folder = r"C:/Code/Python/Digit_test_dataset-master/test"
    output_csv = "digit_predictions.csv"

    train_and_save_model(model_path)
    predict_custom_images(model_path, image_folder, output_csv)
    